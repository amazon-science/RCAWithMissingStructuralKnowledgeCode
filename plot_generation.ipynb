{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a73bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab81da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load experiment data === #\n",
    "accuracy_vs_anomaly = np.load(\"./results/vary_anomaly_strength_results.npy\", allow_pickle=True).item()\n",
    "anomaly_values = accuracy_vs_anomaly[\"config\"][\"anomaly_values\"]\n",
    "number_trials = accuracy_vs_anomaly[\"config\"][\"number_trials\"]\n",
    "\n",
    "# === Plot: Accuracy vs Anomaly Parameter === #\n",
    "y_data = {\n",
    "    label: (\n",
    "        [accuracy_vs_anomaly[val][metric] / number_trials for val in anomaly_values],\n",
    "        marker\n",
    "    )\n",
    "    for label, (metric, marker, _) in methods.items() if metric in accuracy_vs_anomaly[anomaly_values[0]]\n",
    "}\n",
    "\n",
    "plot_line(\n",
    "    x=anomaly_values,\n",
    "    y_dict=y_data,\n",
    "    xlabel=\"Anomaly strength (Nr. standard deviations)\",\n",
    "    ylabel=\"Pct. correctly identified RC\",\n",
    "    output_path=\"./results/accuracy_vs_anomaly.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413233cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load experiment data === #\n",
    "accuracy_vs_size = np.load(\"./results/vary_graph_size_results.npy\", allow_pickle=True).item()\n",
    "number_of_nodes = accuracy_vs_size[\"config\"][\"number_of_nodes\"]\n",
    "number_trials = accuracy_vs_size[\"config\"][\"number_trials\"]\n",
    "\n",
    "# === Plot: Accuracy vs Graph Size === #\n",
    "y_data_size = {\n",
    "    label: (\n",
    "        [accuracy_vs_size[n][metric] / number_trials for n in number_of_nodes],\n",
    "        marker\n",
    "    )\n",
    "    for label, (metric, marker, _) in methods.items() if metric in accuracy_vs_size[number_of_nodes[0]]\n",
    "}\n",
    "\n",
    "plot_line(\n",
    "    x=number_of_nodes,\n",
    "    y_dict=y_data_size,\n",
    "    xlabel=\"Number of nodes\",\n",
    "    ylabel=\"Pct. correctly identified RC\",\n",
    "    output_path=\"./results/accuracy_vs_size.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffd933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load experiment data === #\n",
    "runtime_data = np.load(\"./results/vary_anomaly_strength_results.npy\", allow_pickle=True).item()\n",
    "runtime_anomaly = 3.0  # Fixed value for timing plots\n",
    "\n",
    "# === Plot: Runtime Boxplot === #\n",
    "runtime_times = [\n",
    "    runtime_data[runtime_anomaly][time_key]\n",
    "    for _, (_, _, time_key) in methods.items()\n",
    "]\n",
    "runtime_labels = [\"SCORE\\n ORDERING\", \n",
    "                  \"Cholesky\", \n",
    "                  \"Traversal\", \n",
    "                  \"SMOOTH\\n TRAVERSAL\", \n",
    "                  \"Counter-\\n factual\", \n",
    "                  \"Circa\"]\n",
    "\n",
    "plot_runtime_boxplot(\n",
    "    times=runtime_times,\n",
    "    labels=runtime_labels,\n",
    "    output_path=\"./results/runtime_boxplot.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328807a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load sock-shop results === #\n",
    "sock_shop_results = np.load(\"./results/cluster_results/sock_shop_results.npy\", allow_pickle=True).item()\n",
    "methods = [\n",
    "    \"traversal_correct\", \n",
    "    \"smooth_traversal_correct\", \n",
    "    \"counterfactual_contribution_correct\", \n",
    "    \"circa_correct\", \n",
    "    \"cholesky_correct\", \n",
    "    \"score_ordering_correct\", \n",
    "    \"rcd_correct\", \n",
    "    \"epsilon_diagnosis_correct\"\n",
    "] # change to include only the methods you ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5cc9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Display table of top-k recall results === #\n",
    "sock_shop_results = {k: sock_shop_results[k] for k in [\"cpu\", \"delay\", \"disk\", \"loss\", \"mem\"]}\n",
    "for k in sock_shop_results.keys():\n",
    "    sock_shop_results[k] = {subk: sock_shop_results[k][subk] for subk in methods}\n",
    "\n",
    "results_df = pd.DataFrame(sock_shop_results)/25\n",
    "results_df = results_df.sort_index()\n",
    "print(results_df.round(2).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rca-missing-knowledge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
